{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145b6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import classification_report, roc_auc_score, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from scipy.sparse import hstack\n",
    "from model_components import DenseCT, TextFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "109dcc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv(\"dataset/processed/synthetic-dog-breed-health-data-clean.csv\")\n",
    "\n",
    "# preprocess some fields\n",
    "df[\"Healthy_bin\"] = df[\"Healthy\"].str.lower().map({\"yes\":1, \"no\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de766c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Combine text fields into a single field\n",
    "def combine_text(row):\n",
    "    parts = []\n",
    "    for c in [\"Medications\", \"Seizures\"]:\n",
    "        val = row.get(c, None)\n",
    "        if pd.notna(val):\n",
    "            s = str(val).strip()\n",
    "            if s:\n",
    "                parts.append(s)\n",
    "    return \" | \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55c5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to create the 'notes' column\n",
    "df[\"notes\"] = df.apply(combine_text, axis=1)\n",
    "\n",
    "# check if 'user_text' column exists, if not create it with empty strings\n",
    "if \"user_text\" not in df.columns:\n",
    "    df[\"user_text\"] = \"\"\n",
    "\n",
    "# feature columns\n",
    "common_num = [\"Age\", \"Weight (lbs)\", \"Daily Walk Distance (miles)\",\n",
    "              \"Hours of Sleep\", \"Annual Vet Visits\", \"Average Temperature (F)\"]\n",
    "common_cat = [\"Breed\", \"Breed Size\", \"Sex\", \"Spay/Neuter Status\",\n",
    "              \"Owner Activity Level\" if \"Owner Activity Level\" in df.columns else None,\n",
    "              \"Other Pets in Household\" if \"Other Pets in Household\" in df.columns else None]\n",
    "# Ensure only existing columns are included\n",
    "common_cat = [c for c in common_cat if c and c in df.columns]\n",
    "\n",
    "# define transformers\n",
    "num_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", min_frequency=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199704b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make preprocessor function\n",
    "def make_preprocessor(num_cols, cat_cols):\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_tf, [c for c in num_cols if c in df.columns]),\n",
    "            (\"cat\", cat_tf, [c for c in cat_cols if c in df.columns]),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    ), TfidfVectorizer(ngram_range=(1,2), max_features=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abc43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Activity ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Active       0.33      0.32      0.33       121\n",
      "         Low       0.26      0.22      0.24       121\n",
      "    Moderate       0.25      0.22      0.23       114\n",
      " Very Active       0.26      0.34      0.29       110\n",
      "\n",
      "    accuracy                           0.27       466\n",
      "   macro avg       0.27      0.28      0.27       466\n",
      "weighted avg       0.27      0.27      0.27       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Daily Activity Level (multi-class classification)\n",
    "X = df.copy()\n",
    "X[\"__joined_text__\"] = (X[\"notes\"].fillna(\"\") + \" \" + X.get(\"user_text\",\"\").fillna(\"\"))\n",
    "y_act = X[\"Daily Activity Level\"].astype(str)\n",
    "\n",
    "pre_ct, tfidf = make_preprocessor(common_num, common_cat)\n",
    "ct_feat   = DenseCT(pre_ct)\n",
    "text_feat = TextFeaturizer(tfidf)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_act, test_size=0.2, stratify=y_act, random_state=42)\n",
    "ct_feat.fit(X_train, y_train)\n",
    "text_feat.fit(X_train, y_train)\n",
    "\n",
    "le_act = LabelEncoder().fit(y_train)\n",
    "Xtr = hstack([ct_feat.transform(X_train), text_feat.transform(X_train)])\n",
    "Xva = hstack([ct_feat.transform(X_val),   text_feat.transform(X_val)])\n",
    "\n",
    "clf_act = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"saga\")\n",
    "clf_act.fit(Xtr, le_act.transform(y_train))\n",
    "pred_act = le_act.inverse_transform(clf_act.predict(Xva))\n",
    "print(\"=== Activity ===\")\n",
    "print(classification_report(y_val, pred_act, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a04deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Diet ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Hard food       0.23      0.25      0.24       111\n",
      " Home cooked       0.21      0.21      0.21       118\n",
      "Special diet       0.22      0.29      0.25       111\n",
      "    Wet food       0.29      0.19      0.23       126\n",
      "\n",
      "    accuracy                           0.23       466\n",
      "   macro avg       0.24      0.24      0.23       466\n",
      "weighted avg       0.24      0.23      0.23       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Diet (multi-class classification)\n",
    "X2 = df.copy()\n",
    "X2[\"__joined_text__\"] = (X2[\"notes\"].fillna(\"\") + \" \" + X2.get(\"user_text\",\"\").fillna(\"\"))\n",
    "y_diet = X2[\"Diet\"].astype(str)\n",
    "\n",
    "ct2, tfidf2 = make_preprocessor(common_num, [c for c in common_cat if c != \"Diet\"])\n",
    "ct2_feat = DenseCT(ct2)\n",
    "txt2_feat = TextFeaturizer(tfidf2)\n",
    "\n",
    "X2_tr, X2_va, y2_tr, y2_va = train_test_split(X2, y_diet, test_size=0.2, stratify=y_diet, random_state=42)\n",
    "ct2_feat.fit(X2_tr, y2_tr)\n",
    "txt2_feat.fit(X2_tr, y2_tr)\n",
    "\n",
    "le_diet = LabelEncoder().fit(y2_tr)\n",
    "X2tr = hstack([ct2_feat.transform(X2_tr), txt2_feat.transform(X2_tr)])\n",
    "X2va = hstack([ct2_feat.transform(X2_va), txt2_feat.transform(X2_va)])\n",
    "\n",
    "clf_diet = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"saga\").fit(X2tr, le_diet.transform(y2_tr))\n",
    "pred_diet = le_diet.inverse_transform(clf_diet.predict(X2va))\n",
    "print(\"=== Diet ===\")\n",
    "print(classification_report(y2_va, pred_diet, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeece615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Play Time ===\n",
      "R2= -0.1375381216701299 MAE= 0.9031197343148666\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Play Time (hrs) (regression)\n",
    "y_play = df[\"Play Time (hrs)\"].astype(float)\n",
    "X3 = df.copy()\n",
    "X3[\"__joined_text__\"] = (X3[\"notes\"].fillna(\"\") + \" \" + X3.get(\"user_text\",\"\").fillna(\"\"))\n",
    "\n",
    "ct3, tfidf3 = make_preprocessor(common_num, common_cat)\n",
    "ct3_feat = DenseCT(ct3)\n",
    "txt3_feat = TextFeaturizer(tfidf3)\n",
    "\n",
    "X3_tr, X3_va, y3_tr, y3_va = train_test_split(X3, y_play, test_size=0.2, random_state=42)\n",
    "ct3_feat.fit(X3_tr, y3_tr)\n",
    "txt3_feat.fit(X3_tr, y3_tr)\n",
    "\n",
    "X3tr_sparse = hstack([ct3_feat.transform(X3_tr), txt3_feat.transform(X3_tr)]).tocsr()\n",
    "X3va_sparse = hstack([ct3_feat.transform(X3_va), txt3_feat.transform(X3_va)]).tocsr()\n",
    "\n",
    "reg_play = HistGradientBoostingRegressor().fit(X3tr_sparse.toarray(), y3_tr)\n",
    "y3_pred = reg_play.predict(X3va_sparse.toarray())\n",
    "\n",
    "print(\"=== Play Time ===\")\n",
    "print(\"R2=\", r2_score(y3_va, y3_pred), \"MAE=\", mean_absolute_error(y3_va, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff97de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Healthy ===\n",
      "ROC-AUC= 0.8526914300677065\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Healthy (binary classification)\n",
    "y_h = df[\"Healthy_bin\"].astype(int)\n",
    "X4 = df.copy()\n",
    "X4[\"__joined_text__\"] = (X4[\"notes\"].fillna(\"\") + \" \" + X4.get(\"user_text\",\"\").fillna(\"\"))\n",
    "\n",
    "ct4, tfidf4 = make_preprocessor(common_num, common_cat)\n",
    "ct4_feat = DenseCT(ct4)\n",
    "txt4_feat = TextFeaturizer(tfidf4)\n",
    "\n",
    "X4_tr, X4_va, y4_tr, y4_va = train_test_split(X4, y_h, test_size=0.2, stratify=y_h, random_state=42)\n",
    "ct4_feat.fit(X4_tr, y4_tr)\n",
    "txt4_feat.fit(X4_tr, y4_tr)\n",
    "\n",
    "clf_h = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"saga\")\n",
    "clf_h.fit(hstack([ct4_feat.transform(X4_tr), txt4_feat.transform(X4_tr)]), y4_tr)\n",
    "proba_h = clf_h.predict_proba(hstack([ct4_feat.transform(X4_va), txt4_feat.transform(X4_va)]))[:, 1]\n",
    "print(\"=== Healthy ===\")\n",
    "print(\"ROC-AUC=\", roc_auc_score(y4_va, proba_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bd07ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> wooftalk_multi_tasks.joblib\n"
     ]
    }
   ],
   "source": [
    "# save all components\n",
    "bundle = {\n",
    "    \"activity\": {\"ct\": ct_feat, \"tfidf\": text_feat, \"clf\": clf_act, \"label_encoder\": le_act},\n",
    "    \"diet\":     {\"ct\": ct2_feat, \"tfidf\": txt2_feat, \"clf\": clf_diet, \"label_encoder\": le_diet},\n",
    "    \"play\":     {\"ct\": ct3_feat, \"tfidf\": txt3_feat, \"reg\": reg_play},\n",
    "    \"healthy\":  {\"ct\": ct4_feat, \"tfidf\": txt4_feat, \"clf\": clf_h},\n",
    "}\n",
    "joblib.dump(bundle, \"wooftalk_multi_tasks.joblib\")\n",
    "print(\"Saved -> wooftalk_multi_tasks.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv-conclase)",
   "language": "python",
   "name": "conclase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
